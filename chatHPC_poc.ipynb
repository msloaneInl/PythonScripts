{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '5mdim-8qu4h-pq2g7-ivhl6-memyi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an OpenAI compatible API client for making calls into one of the HPC's language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.hpc.inl.gov/llm/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the list of language models that can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = client.models.list()\n",
    "print(f'model_list: {model_list}')\n",
    "model_names = [x.id for x in model_list.data]\n",
    "print(f'model names: {model_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = model_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemRoleContent= \"You are a technical assistant, skilled in explaining complex programming concepts with everyday language.\"\n",
    "\n",
    "descriptionPrompt = \"Given the following list of variable names, generate a sentence description for each.\"\n",
    "\n",
    "friendlyNamesPrompt = \"\"\"Given the following list of variable names, separate each variable name into words with a space between words. \n",
    "     Search through each variable name to determine if any substring matches a well known english word.\n",
    "     Interpret the use of camel case or Pascal case within a variable name as defining a word boundary.\n",
    "     Interpret the _ character within a variable name as defining a word boundary.\n",
    "     For example ApprRequestForm_ID would be separated into the following words: Appr Request Form ID\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleColumnNames = \"\"\"\n",
    "AccessRequest\n",
    "ApprRequestForm_ID\n",
    "Area_ID\n",
    "Building\n",
    "Escort_ID\n",
    "LOGEndDate\n",
    "LOGStartDate\n",
    "Purpose\n",
    "Request_Area_ID\n",
    "Room\n",
    "ApprRequestForm_ID\n",
    "Comments\n",
    "DtAction\n",
    "LOGEndDate\n",
    "LOGStartDate\n",
    "NTID\n",
    "Other_ID\n",
    "Request_StateAction_ID\n",
    "SNumber\n",
    "StateAction_ID\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate element level descriptions\n",
    "completion = client.chat.completions.create(model=GPT_MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": systemRoleContent},\n",
    "    {\"role\": \"user\", \"content\": descriptionPrompt + exampleColumnNames}\n",
    "  ]\n",
    ")\n",
    "descriptions = completion.choices[0].message.content\n",
    "\n",
    "# Generate friendly names\n",
    "completion = client.chat.completions.create(model=GPT_MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": systemRoleContent},\n",
    "    {\"role\": \"user\", \"content\": friendlyNamesPrompt + exampleColumnNames}\n",
    "  ]\n",
    ")\n",
    "friendlyNames = completion.choices[0].message.content\n",
    "\n",
    "\n",
    "print(f\"Descriptions:\\n{descriptions.replace('his variable ', 'his element ')}\")\n",
    "print(f\"\\nFriendly Names:\\n{friendlyNames}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
